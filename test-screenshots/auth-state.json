{
  "cookies": [],
  "origins": [
    {
      "origin": "http://localhost:8083",
      "localStorage": [
        {
          "name": "hyokai-saved-contexts",
          "value": "[{\"id\":\"ctx_1766042946239_ftfmir\",\"name\":\"test\",\"content\":\"test\",\"createdAt\":1766042946375,\"updatedAt\":1766042946375},{\"id\":\"ctx_1765951064547_p91g6i\",\"name\":\"hyokai\",\"content\":\"# APP_CONTEXT.md - Hyokai Technical Reference\\n\\n## Project Overview\\n\\n**Hyokai** (氷解 - \\\"ice melt\\\") is a prompt transformation tool that converts natural language requests into precise technical specifications for AI coding agents and general assistants. Supports dual modes (coding/prompting), multi-model comparison, and bilingual UI (EN/JP).\\n\\n## Tech Stack\\n\\n| Layer | Technology |\\n|-------|------------|\\n| **Frontend** | React 18.3, TypeScript 5.8, Vite 5.4 |\\n| **Styling** | Tailwind CSS 3.4, shadcn-ui (Radix UI), Lucide icons |\\n| **State** | React Context, custom hooks, localStorage persistence |\\n| **Backend** | Supabase Edge Functions (Deno), OpenRouter API |\\n| **Build** | Vite + SWC, ESLint 9, PostCSS |\\n\\n**Key Dependencies**: `@tanstack/react-query`, `react-hook-form`, `zod`, `next-themes`, `sonner`\\n\\n## Core Features\\n\\n- Transform vague prompts into structured technical specifications\\n- **Coding Mode**: Optimized for IDE agents (Claude Code, Cursor, Copilot)\\n- **Prompting Mode**: Optimized for general AI (ChatGPT, Claude, Gemini)\\n- **Model Comparison**: Run same prompt through 2-4 models simultaneously\\n- **History**: localStorage-based session history with restore capability\\n- **i18n**: Full English/Japanese translation support\\n- Real-time elapsed time tracking per transformation\\n\\n## Architecture & Structure\\n\\n**Architecture**: React SPA + Serverless Edge Function\\n\\n```\\nsrc/\\n├── pages/Index.tsx          # Main orchestrator - all features integrated here\\n├── components/\\n│   ├── ui/                  # shadcn-ui primitives (50+ components)\\n│   ├── Header.tsx           # App branding\\n│   ├── PromptInput.tsx      # User input textarea\\n│   ├── OutputPanel.tsx      # Single model output display\\n│   ├── ComparisonPanel.tsx  # Multi-model grid output\\n│   ├── ModelSelector.tsx    # Single model dropdown\\n│   ├── ModelMultiSelector.tsx # Multi-select checkboxes\\n│   ├── ModeToggle.tsx       # Coding/Prompting switch\\n│   ├── CompareToggle.tsx    # Single/Compare switch\\n│   ├── LanguageSelector.tsx # EN/JP toggle\\n│   └── HistoryPanel.tsx     # History sidebar\\n├── contexts/\\n│   ├── ModeContext.tsx      # Task mode state (coding|prompting)\\n│   └── LanguageContext.tsx  # Language state (en|jp) + t() function\\n├── hooks/\\n│   ├── usePromptTransformer.ts  # Single model transformation\\n│   └── useModelComparison.ts    # Parallel multi-model transformation\\n├── lib/\\n│   ├── models.ts            # AIModel[] definitions\\n│   ├── translations.ts      # EN/JP string map\\n│   ├── history.ts           # localStorage CRUD for history\\n│   └── utils.ts             # clsx/tailwind-merge helper\\n└── integrations/supabase/   # Supabase client setup\\n\\nsupabase/functions/\\n└── transform-prompt/index.ts  # Edge function: LLM API integration\\n```\\n\\n## Data Models / Schema\\n\\n```typescript\\n// AI Model Definition\\ninterface AIModel {\\n  id: string;           // OpenRouter model ID\\n  name: string;         // Display name\\n  provider: string;     // \\\"Google\\\" | \\\"Anthropic\\\"\\n  thinking?: boolean;   // Extended reasoning mode\\n}\\n\\n// History Entry (localStorage)\\ninterface HistoryEntry {\\n  id: string;\\n  timestamp: number;\\n  input: string;\\n  taskMode: 'coding' | 'prompting';\\n  result: SingleModelResult | CompareModelResult;\\n}\\n\\ninterface SingleModelResult {\\n  type: 'single';\\n  modelName: string;\\n  modelProvider: string;\\n  output: string;\\n  elapsedTime: number | null;\\n}\\n\\ninterface CompareModelResult {\\n  type: 'compare';\\n  results: Array<{\\n    modelName: string;\\n    modelProvider: string;\\n    output: string | null;\\n    error: string | null;\\n    elapsedTime: number | null;\\n  }>;\\n}\\n\\n// API Request (transform-prompt)\\n{ userPrompt: string, model: string, mode: string, thinking: boolean }\\n\\n// API Response\\n{ result: string } | { error: string }\\n```\\n\\n## Key Workflows\\n\\n### Single Model Transformation\\n```\\nPromptInput → usePromptTransformer.transform()\\n  → supabase.functions.invoke('transform-prompt')\\n    → OpenRouter API (system prompt + user prompt)\\n  → OutputPanel displays result\\n  → Auto-save to history\\n```\\n\\n### Model Comparison\\n```\\nModelMultiSelector (2-4 models) → useModelComparison.compare()\\n  → Promise.all(models.map(transformWithModel))\\n    → Concurrent API calls, individual timers\\n  → ComparisonPanel updates as each completes\\n  → Auto-save all results to history\\n```\\n\\n### State Persistence (localStorage keys)\\n- `hyokai-mode`: 'coding' | 'prompting'\\n- `hyokai-language`: 'en' | 'jp'\\n- `hyokai-selected-model-index`: number\\n- `hyokai-compare-model-indices`: number[]\\n- `hyokai-history`: HistoryEntry[] (max 50)\\n\\n## Development Context\\n\\n**Environment Variables** (`.env`):\\n```\\nVITE_SUPABASE_URL=https://[project].supabase.co\\nVITE_SUPABASE_PUBLISHABLE_KEY=[anon-key]\\n```\\n\\n**Edge Function Secrets** (Supabase dashboard):\\n- `OPENROUTER_API_KEY`: Required for LLM API calls\\n\\n**Scripts**:\\n```bash\\nnpm run dev      # Vite dev server (port 8080)\\nnpm run build    # Production build to /dist\\nnpm run lint     # ESLint check\\n```\\n\\n**Key Config**:\\n- TypeScript: `strict: false`, path alias `@/` → `src/`\\n- Tailwind: Dark mode via class, custom ice-theme colors\\n- Vite: SWC for fast compilation\\n\\n**Available Models** (hardcoded in `lib/models.ts`):\\n1. Gemini 3 Pro (Google)\\n2. Gemini 3 Pro + Thinking\\n3. Claude Sonnet 4.5 (Anthropic)\\n4. Claude Sonnet 4.5 + Thinking\\n\\n**System Prompts** (in edge function):\\n- `CODING_MODE_SYSTEM_PROMPT`: 167 lines - transforms for IDE coding agents\\n- `PROMPTING_MODE_SYSTEM_PROMPT`: 388 lines - transforms for general AI assistants\\n\\nBoth enforce: transform-only output, no preamble, add structure/criteria/edge cases.\\n\\n## Critical Implementation Notes\\n\\n- History saves automatically when `isLoading` transitions false → detected via `useRef` + `useEffect`\\n- Compare mode uses per-model timers via `Map<number, NodeJS.Timeout>`\\n- Model selection stores index (not ID) because thinking variants share same model ID\\n- Edge function strips unwanted headers from LLM output (indexOf + regex fallback)\\n- No backend database - all persistence is client-side localStorage\\n- Deployed via Vercel (frontend) + Supabase CLI (edge functions)\\n\",\"createdAt\":1765951064646,\"updatedAt\":1765951067066}]"
        },
        {
          "name": "sb-znjqpxlijraodmjrhqaz-auth-token",
          "value": "{\"access_token\":\"eyJhbGciOiJIUzI1NiIsImtpZCI6IjQrcFlYeHlCMWNkVEZsQWwiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL3puanFweGxpanJhb2RtanJocWF6LnN1cGFiYXNlLmNvL2F1dGgvdjEiLCJzdWIiOiJjN2NjODZmNy0wNmNjLTQyOTktYTk3MS03OWZjZThmZDhkNDQiLCJhdWQiOiJhdXRoZW50aWNhdGVkIiwiZXhwIjoxNzY2MTIxMzY2LCJpYXQiOjE3NjYxMTc3NjYsImVtYWlsIjoicmVpbXV0b21vbmFyaUBnbWFpbC5jb20iLCJwaG9uZSI6IiIsImFwcF9tZXRhZGF0YSI6eyJwcm92aWRlciI6ImVtYWlsIiwicHJvdmlkZXJzIjpbImVtYWlsIl19LCJ1c2VyX21ldGFkYXRhIjp7ImVtYWlsIjoicmVpbXV0b21vbmFyaUBnbWFpbC5jb20iLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwicGhvbmVfdmVyaWZpZWQiOmZhbHNlLCJzdWIiOiJjN2NjODZmNy0wNmNjLTQyOTktYTk3MS03OWZjZThmZDhkNDQifSwicm9sZSI6ImF1dGhlbnRpY2F0ZWQiLCJhYWwiOiJhYWwxIiwiYW1yIjpbeyJtZXRob2QiOiJwYXNzd29yZCIsInRpbWVzdGFtcCI6MTc2NjExNzc2Nn1dLCJzZXNzaW9uX2lkIjoiNWViY2U2OTctMmEzYi00YjEyLWJiMmMtNDc2YTNmYmY5ZDI4IiwiaXNfYW5vbnltb3VzIjpmYWxzZX0.dzcwKrJFnBIGHIuxqza5vxW9pVMAC2-69DiNUGyNYT8\",\"token_type\":\"bearer\",\"expires_in\":3600,\"expires_at\":1766121366,\"refresh_token\":\"lej2koaraklt\",\"user\":{\"id\":\"c7cc86f7-06cc-4299-a971-79fce8fd8d44\",\"aud\":\"authenticated\",\"role\":\"authenticated\",\"email\":\"reimutomonari@gmail.com\",\"email_confirmed_at\":\"2025-12-17T03:51:31.053498Z\",\"phone\":\"\",\"confirmation_sent_at\":\"2025-12-17T03:51:05.665739Z\",\"confirmed_at\":\"2025-12-17T03:51:31.053498Z\",\"last_sign_in_at\":\"2025-12-19T04:16:06.710475262Z\",\"app_metadata\":{\"provider\":\"email\",\"providers\":[\"email\"]},\"user_metadata\":{\"email\":\"reimutomonari@gmail.com\",\"email_verified\":true,\"phone_verified\":false,\"sub\":\"c7cc86f7-06cc-4299-a971-79fce8fd8d44\"},\"identities\":[{\"identity_id\":\"76593e30-5375-495f-8bc5-7e161375e7ef\",\"id\":\"c7cc86f7-06cc-4299-a971-79fce8fd8d44\",\"user_id\":\"c7cc86f7-06cc-4299-a971-79fce8fd8d44\",\"identity_data\":{\"email\":\"reimutomonari@gmail.com\",\"email_verified\":true,\"phone_verified\":false,\"sub\":\"c7cc86f7-06cc-4299-a971-79fce8fd8d44\"},\"provider\":\"email\",\"last_sign_in_at\":\"2025-12-17T03:51:05.659062Z\",\"created_at\":\"2025-12-17T03:51:05.65912Z\",\"updated_at\":\"2025-12-17T03:51:05.65912Z\",\"email\":\"reimutomonari@gmail.com\"}],\"created_at\":\"2025-12-17T03:51:05.641285Z\",\"updated_at\":\"2025-12-19T04:16:06.71757Z\",\"is_anonymous\":false},\"weak_password\":null}"
        },
        {
          "name": "hyokai-selected-model-index",
          "value": "5"
        },
        {
          "name": "hyokai-input-height",
          "value": "200"
        },
        {
          "name": "hyokai-active-context-id",
          "value": "ctx_1766042946239_ftfmir"
        },
        {
          "name": "hyokai-github-repos",
          "value": "[{\"repository\":{\"id\":\"repo_1765943645888_uesgtn\",\"owner\":\"shibakouen\",\"name\":\"hyokai\",\"fullName\":\"shibakouen/hyokai\",\"defaultBranch\":\"main\",\"lastRefreshed\":1765943648914},\"cache\":null}]"
        },
        {
          "name": "hyokai-github-settings",
          "value": "{\"enabled\":true,\"autoIncludeInCoding\":true,\"maxContextTokens\":16000}"
        },
        {
          "name": "hyokai-user-context",
          "value": "test"
        }
      ]
    }
  ]
}